Executive Summary of Nginx
    - Event-based, not follow Apache's style of spawning new processes or threads for each web page request. 
    - Uses multiplexing and event notifications heavily, and dedicates specific tasks to separate processes.
    - Connections are processed in a highly efficient run-loop in a limited number of single-threaded processes called workers.
        *  Within each worker nginx can handle many thousands of concurrent connections and requests per second.

Lesson Learned:
    - there is always room for improvement.
    - initial prototype of a new architecture, and the initial code structure, are vitally important for the future of a software product.
    - development should be focused. 
        * The Windows version of nginx is probably a good example of how it is worth avoiding the dilution of development efforts 
          on something that is neither the developer's core competence or the target application.


nginx's modular architecture 
    - generally allows developers to extend the set of web server features without modifying the nginx core. 
    - nginx modules include
        * core modules
        * event modules
            - Provide a particular OS-dependent event notification mechanism like kqueue or epoll
        * phase handlers
        * protocols
            - Protocol modules allow nginx to communicate through HTTPS, TLS/SSL, SMTP, POP3 and IMAP.
        * variable handlers
        * filters
        * upstreams
        * load balancers

When nginx handles an HTTP request, it passes it through a number of processing phases. 
    - At each phase there are handlers to call. In general, phase handlers process a request and produce the relevant output. 

Phase handlers typically do four things: get the location configuration, generate an appropriate response, send the header, and send the body. A handler has one argument: a specific structure describing the request. A request structure has a lot of useful information about the client request, such as the request method, URI, and header.

filter chain
      
Config of nginx
    - main configuration file is usually called nginx.conf
    - The configuration files are initially read and verified by the master process. 


nginx uses event notification mechanisms and a number of disk I/O performance enhancements in Linux, Solaris and BSD-based operating systems, 
    - like kqueue, epoll, and event ports. 
    - The goal is to provide as many hints to the operating system as possible, in regards to obtaining timely asynchronous feedback for 
        * inbound and outbound traffic
        * disk operations
        * reading from or writing to sockets
        * timeouts and so on. 
    - The usage of different methods for multiplexing and advanced I/O operations is heavily optimized for every Unix-based operating system nginx runs on.
    
the nginx codebase consists of a core and a number of modules. 
    - The core of nginx is responsible for providing the foundation of the web server, web and mail reverse proxy functionalities; 
    - it enables the use of underlying network protocols, builds the necessary run-time environment, and ensures seamless interaction between different modules. 
    - However, most of the protocol- and application-specific features are done by nginx modules, not the core.
    
Nginx internal
    - Internally, nginx processes connections through a pipeline, or chain, of modules. 
    - In other words, for every operation there's a module which is doing the relevant work; 
        e.g., compression, modifying content, executing server-side includes, communicating to upstream application servers through FastCGI or uwsgi protocols, 
              or talking to memcached.

Reverse proxy 
    - a type of proxy server that retrieves resources on behalf of a client from one or more servers. 
    - These resources are then returned to the client as though they originated from the server itself (or servers themselves).
    - Compare with forward proxy
        * Forward proxy acts as an intermediary for its (usually nearby) associated client(s) and returns to them resources accessible on the Internet 
        * Reverse proxy acts as an intermediary for its (usually nearby) associated server(s) and only returns resources provided by those associated server(s).

Static web page (sometimes called a flat page/stationary page) 
    - a web page that is delivered to the user exactly as stored
    - in contrast to dynamic web pages which are generated by a web application.
    - Static web pages are often HTML documents stored as files in the file system and made available by the web server over HTTP

One of the biggest challenges for a website architect has always been concurrency. 
Since the beginning of web services, the level of concurrency has been continuously growing. 
It's common for a popular website to serve hundreds of thousands and even millions of simultaneous users. 

Traditional process- or thread-based models of handling concurrent connections involve 
handling each connection with a separate process or thread, and blocking on network or input/output operations. 

Depending on the application, it can be very inefficient in terms of memory and CPU consumption. 
Spawning a separate process or thread requires preparation of a new runtime environment, including 
allocation of heap and stack memory, and the creation of a new execution context.

Additional CPU time is also spent creating these items, which can eventually lead to poor performance due to thread thrashing on excessive context switching. 
All of these complications manifest themselves in older web server architectures like Apache's. 
This is a tradeoff between offering a rich set of generally applicable features and optimized usage of server resources.


It was actually inspired by the ongoing development of advanced event-based mechanisms in a variety of operating systems. 
What resulted is a modular, event-driven, asynchronous, single-threaded, non-blocking architecture which 
became the foundation of nginx code.

nginx 
    - uses multiplexing and event notifications heavily, and dedicates specific tasks to separate processes.
    - Connections are processed in a highly efficient run-loop in a limited number of single-threaded processes called workers. 
        * Within each worker nginx can handle many thousands of concurrent connections and requests per second.

The nginx worker code 
    - includes the core and the functional modules. 
    - The core of nginx is responsible for maintaining a tight run-loop and executing appropriate sections of modules' code on each stage of request processing. 
    - Modules constitute most of the presentation and application layer functionality; include:
        * read from and write to the network and storage, 
        * transform content
        * do outbound filtering
        * apply server-side include actions 
        * pass the requests to the upstream servers when proxying is activated.

A typical HTTP request processing cycle looks like the following.
    - Client sends HTTP request.
    - nginx core chooses the appropriate phase handler based on the configured location matching the request.
    - If configured to do so, a load balancer picks an upstream server for proxying.
    - Phase handler does its job and passes each output buffer to the first filter.
    - First filter passes the output to the second filter.
    - Second filter passes the output to third (and so on).
    - Final response is sent to the client.

A more detailed view of processing an HTTP request might look like this:
    - Initialize request processing.
    - Process header.
    - Process body.
    - Call the associated handler.
    - Run through the processing phases.

Why Apache is not suitable?
    - Apache became a general purpose web server focusing on having many different features, a variety of third-party extensions, and universal applicability to practically any kind of web application development. 
    - However, nothing comes without a price and the downside to having such a rich and universal combination of tools in a single piece of software is less scalability because of increased CPU and memory usage per connection.
    
Daniel Kegel
    C10K    solving the C10K problem of 10,000 simultaneous connections, 
    
nginx is event-based, so it does not follow Apache's style of spawning new processes or threads for each web page request. 
    - The end result is that even as load increases, memory and CPU usage remain manageable.
    - nginx can now deliver tens of thousands of concurrent connections on a server with typical hardware.
    
web architects have embraced the idea of decoupling and separating their application infrastructure from the web server. 
   However, what would previously exist in the form of a LAMP (Linux, Apache, MySQL, PHP, Python or Perl)-based website, 
   might now become not merely a LEMP-based one (`E' standing for `Engine x'), 
   but more and more often an exercise in pushing the web server to the edge of the infrastructure and integrating the same 
   or a revamped set of applications and database tools around it in a different way.
* nginx is very well suited for this, as it provides the key features necessary to conveniently 
    - offload concurrency
    - latency processing
    - SSL (secure sockets layer)
    - static content
    - compression and caching, 
    - connections and requests throttling, and 
    - even HTTP media streaming from the application layer to a much more efficient edge web server layer. 
    - also allows integrating directly with memcached/Redis or other "NoSQL" solutions, to boost performance when serving a large number of concurrent users.

nginx:
    - written entirely from scratch in the C programming language.
    - nginx has its own libraries and with its standard modules does not use much beyond the system's C library, except for zlib, PCRE and OpenSSL
